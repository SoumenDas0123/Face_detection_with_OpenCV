{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OpenCV library\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the paths with filename\n",
    "imagePath = 'PinkFloyd.jpg'\n",
    "cascadeClassifierPath = 'haarcascade_frontalface_default.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the haar cascade\n",
    "cascadeClassifier = cv2.CascadeClassifier(cascadeClassifierPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for face detection\n",
    "cascadeClassifier.detectMultiScale(image, faceDetections, scaleFactor, minNeighbors, flags, minSize, maxSize)  \n",
    "\n",
    "1. **scaleFactor**: Since some faces may be closer to the camera, they would appear bigger than other faces in the background, the scale factor compensates for this\n",
    "specifying how much the image size is reduced at each image scale. The model has a fixed size defined during training in the haarcascade_frontalface_default.xml file.\n",
    "By rescaling the input image, you can resize a larger face to a smaller one,making it detectable by the algorithm. Value: 1.1 - 1.4, **Small**-> algorithm will be\n",
    "slow since it is more thorough, **High**-> faster detection with the risk of missing some faces altogether.  \n",
    "2. **minNeighbors**: Specifying how many neighbors each candidate rectangle should have to retain it, Value interval: ~ 3-6, Higher values-> less detections but with\n",
    "higher quality.  \n",
    "3. **flags**: Kind of a heuristic, reject some image regions that contain too few or too much edges and thus can not contain the searched object.  \n",
    "4. **minSize**: Objects smaller than this are ignored,\twe can specify what is the smallest object we want to recognize, 30x30 is the standard.  \n",
    "5. **maxSize**: Objects larger than that are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "image = cv2.imread(imagePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face can be deteced in grayscale images as well, changing the image to greyscale will make it computationally less heavy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change image to grayscale\n",
    "grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect faces in the image\n",
    "detectedFaces = cascadeClassifier.detectMultiScale(grayImage,  scaleFactor=1.1, minNeighbors=5, minSize=(70, 70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 faces!\n"
     ]
    }
   ],
   "source": [
    "# Print the number of detected faces\n",
    "print( \"Found {0} faces!\".format(len(detectedFaces)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a rectangle around the faces\n",
    "'''\n",
    "For green color window (0,255,0) and for border width 5\n",
    "'''\n",
    "for(x,y, width, height) in detectedFaces:\n",
    "    cv2.rectangle(image, (x, y), (x+width, y+height), (0,255,0), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the result\n",
    "cv2.imwrite('PinkFloydResult2.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the result in external window\n",
    "cv2.imshow(\"Faces found\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
